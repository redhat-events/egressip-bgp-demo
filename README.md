This is a detailed README based on the content of your video demo and the files listed in the `redhat-events/egressip-bgp-demo` repository.

-----

# EgressIP with BGP Demo on OpenShift

This repository contains the scripts and configuration files used to demonstrate **granular Egress IP control** within OpenShift, integrating with an external network using **BGP (Border Gateway Protocol)**.

The solution allows operators to assign specific, stable Egress IP addresses to workloads based on their Namespace or Pod labels. These Egress IPs are dynamically advertised to an external BGP peer, ensuring external network devices can correctly route traffic based on policy.

-----

## üöÄ Key Features

  * **Granular Egress Control:** Use `EgressIP` custom resources with **Namespace and Pod selectors** to tie specific outbound IP addresses to distinct workloads (e.g., separating `dev` and `prod` traffic).
  * **BGP Integration:** The OpenShift network operator leverages BGP to advertise Egress IP routes to an external BGP peer (simulated here by a VM running FRR/VRR).
  * **Multi-Cluster Ready:** The demo script is designed to operate and demonstrate this functionality across multiple OpenShift clusters.
  * **Traffic Verification:** Traffic generated by test pods is monitored in real-time to confirm it is successfully egressing via the assigned IP addresses.

-----

## üõ†Ô∏è Prerequisites

To run this demo, you will need:

1.  **OpenShift Clusters:** Access to an OpenShift cluster (version 4.x or later) with OVN-Kubernetes CNI.
2.  **External BGP Peer:** An external VM or device configured to act as a BGP peer, such as one running **FRR/VRR**.
3.  **Local Tools:** `oc` (OpenShift CLI), `if-top` (or similar network monitoring tool for verification), and shell access to your BGP peer VM.

-----

## üì¶ Repository Contents

| File/Script | Purpose | Description |
| :--- | :--- | :--- |
| `demo.sh` | **Main Demo Script** | Orchestrates the entire setup, application, and cleanup process. |
| `egressip.yaml.tmpl` | **EgressIP Manifests** | Defines the Namespace, EgressIP, and test Pod configurations. Includes selectors for `dev` and `prod` environments. |
| `routeAdvertisement.yaml.tmpl` | **BGP Configuration** | Defines the BGP advertisements, including the ASN and the external BGP peer IP (`10.14.10.99`). |
| `patchNetworkOperator.sh` | **Network Config Patch** | Patches the OpenShift Network Operator to enable BGP and route advertisement capabilities. |
| `setup-peers.sh` | **BGP Peer Setup** | Script to configure the external BGP peer (VM running FRR/VRR). |
| `frr.vm.yaml` | **External VM Definition** | YAML manifest for the external BGP VM configuration (if using OpenShift for the VM). |
| `watch-frr.sh` | **Monitoring Script** | Runs `vtysh` commands in a loop on the BGP peer to monitor route advertisements during the demo. |

-----

## üé¨ Demo Steps

The `demo.sh` script automates the following sequence. The video provides a visual walkthrough of this process.

### 1\. Pre-Configuration and Cleanup

The script first ensures a clean environment by deleting any previous resources and verifies that the BGP peering is currently inactive.

```bash
# Deletes old resources
./demo.sh delete

# Verifies BGP is down
watch frr.sh
# Expected: "Total number of neighbors: 0"
```

### 2\. Prepare Nodes for EgressIP

Cluster nodes must be labeled to be eligible for Egress IP assignment.

```bash
# Extracts all nodes without the label and applies it
for node in $(oc get nodes -l '!k8s.ovn.org/egress-assignable' -o name); do
  oc label node $node k8s.ovn.org/egress-assignable="" --overwrite=true
done
```

### 3\. Enable BGP Advertisements

Patch the Network Operator to enable BGP and advertise the routes.

```bash
oc patch network.operator.openshift.io --type=merge --patch-file patchNetworkOperator.sh
```

### 4\. Configure BGP Peers and Egress Routes

Apply the configuration files that define the BGP peer settings and the Egress IP objects.

  * **`routeAdvertisement.yaml.tmpl`** sets up the BGP peer connection and the ASN for the OpenShift cluster nodes.
  * **`egressip.yaml.tmpl`** creates:
      * Namespaces: `egress-dev` and `egress-prod`.
      * Multiple `EgressIP` objects that bind specific IP ranges (e.g., `10.14.10.100` and `10.14.10.110`) to pods within those namespaces.
      * Test pods that constantly `ping` and `curl` an external target.

<!-- end list -->

```bash
./demo.sh apply
```

### 5\. Verification: Check Route Advertisement

As the `EgressIP` objects are reconciled, the corresponding routes are automatically injected into the cluster nodes' routing tables and advertised via BGP.

  * Run the watcher script on the external VM. You will see the Egress IP routes being dynamically added to the BGP routing table, proving external network reachability.

### 6\. Verification: Check Egress Traffic Flow

Use the `if-top` output on the target external VM to confirm the source IP addresses of the incoming traffic.

  * Observe that traffic from the test pods is correctly sourced from the newly advertised **Egress IP addresses** (e.g., `10.14.10.100` for one workload and `10.14.10.110` for another).

### 7\. Cleanup

Once the demo is complete, run the cleanup step to remove all created resources.

```bash
./demo.sh delete
```
